{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\MNR\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\MNR\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.24.9)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from PyMuPDF) (1.24.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\MNR\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-docx) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\MNR\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mnr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->SpeechRecognition) (2023.11.17)\n",
      "Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
      "   ---------------------------------------- 0.0/32.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/32.8 MB 2.3 MB/s eta 0:00:15\n",
      "    --------------------------------------- 0.4/32.8 MB 6.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.0/32.8 MB 11.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.7/32.8 MB 10.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.6/32.8 MB 14.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.1/32.8 MB 14.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.1/32.8 MB 14.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.1/32.8 MB 14.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.1/32.8 MB 14.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.1/32.8 MB 14.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.1/32.8 MB 14.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.6/32.8 MB 6.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 4.2/32.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.2/32.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.2/32.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.2/32.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.2/32.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.2/32.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.5/32.8 MB 5.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 5.2/32.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.2/32.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.2/32.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.2/32.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.2/32.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.2/32.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.5/32.8 MB 4.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 6.1/32.8 MB 5.2 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 6.5/32.8 MB 5.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 7.1/32.8 MB 5.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 7.6/32.8 MB 6.0 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 8.4/32.8 MB 6.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 9.0/32.8 MB 6.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 9.6/32.8 MB 6.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 9.9/32.8 MB 6.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 10.3/32.8 MB 6.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 10.5/32.8 MB 6.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 10.5/32.8 MB 6.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 11.0/32.8 MB 6.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 11.6/32.8 MB 6.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 12.1/32.8 MB 6.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 12.7/32.8 MB 6.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 13.1/32.8 MB 6.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 13.6/32.8 MB 7.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 14.1/32.8 MB 7.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 14.7/32.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 15.3/32.8 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 15.7/32.8 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 16.1/32.8 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 16.7/32.8 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 16.8/32.8 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 16.8/32.8 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 16.8/32.8 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 16.8/32.8 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 17.0/32.8 MB 9.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 17.5/32.8 MB 9.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 17.9/32.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 18.4/32.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 18.9/32.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 18.9/32.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 18.9/32.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 18.9/32.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 18.9/32.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 19.0/32.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 19.5/32.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 20.0/32.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 20.6/32.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 21.0/32.8 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 21.5/32.8 MB 7.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 22.1/32.8 MB 7.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 22.6/32.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 23.3/32.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 23.8/32.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 24.4/32.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 24.9/32.8 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 25.5/32.8 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 26.0/32.8 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 26.6/32.8 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 27.0/32.8 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 27.3/32.8 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 27.9/32.8 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 28.5/32.8 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 29.3/32.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 29.4/32.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 29.4/32.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 29.4/32.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 29.4/32.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 29.7/32.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 30.2/32.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 31.0/32.8 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 31.8/32.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.4/32.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.8/32.8 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n",
      "Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 164.1/164.1 kB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pyaudio, SpeechRecognition, gTTS\n",
      "Successfully installed SpeechRecognition-3.10.4 gTTS-2.5.3 pyaudio-0.2.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\MNR\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the required Python packages for the project.\n",
    "# - `langchain-google-genai`: Provides integration with Google Generative AI models.\n",
    "# - `langchain`: A framework for managing and using language models.\n",
    "# - `faiss-cpu`: FAISS library for efficient similarity search and clustering.\n",
    "# - `pypdf`: Library for reading and manipulating PDF files.\n",
    "# - `sentence-transformers`: Used for creating embeddings from sentences.\n",
    "# - `langchain-community`: Community-driven extensions and tools for LangChain.\n",
    "# - `pandas`: Essential library for data manipulation and analysis.\n",
    "# - `PyMuPDF`: Provides tools for working with PDF and other document formats.\n",
    "# - `python-docx`: Used for reading and writing Microsoft Word documents.\n",
    "# - `SpeechRecognition`: Library for speech recognition.\n",
    "# - `gTTS`: Google Text-to-Speech library for converting text to speech.\n",
    "# - `pyaudio`: Provides tools for audio input and output.\n",
    "%pip install -U --quiet langchain-google-genai langchain faiss-cpu pypdf sentence-transformers\n",
    "%pip install -U --quiet langchain-community pandas\n",
    "%pip install PyMuPDF\n",
    "%pip install python-docx\n",
    "%pip install SpeechRecognition gTTS pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260c7abd507741f08b84ca7e70f5f09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\MNR\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfc2622c3244460bee0bdf189e54cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd90ad64537a40449cc621fc8957649f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b28a0f8dc9419d8d7910f580e7e94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f9377f42ec4117a000e7e25e6d0837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c342393ea71c43938838500aee9c120a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for the project:\n",
    "# - `os`: Provides functions for interacting with the operating system.\n",
    "# - `pandas`: Data manipulation and analysis library.\n",
    "# - `langchain.document_loaders`: For loading and processing documents.\n",
    "# - `langchain.embeddings`: For generating embeddings from text.\n",
    "# - `langchain`: Core framework for managing and using language models.\n",
    "# - `langchain_google_genai`: For integrating with Google's Generative AI models.\n",
    "# - `langchain.schema`: Defines data structures used by LangChain.\n",
    "# - `docx`: For reading and writing Microsoft Word documents.\n",
    "# - `speech_recognition`: For recognizing speech from audio.\n",
    "# - `gTTS`: Converts text to speech using Google Text-to-Speech.\n",
    "# - `tempfile`: For creating temporary files and directories.\n",
    "# - `io`: Provides core tools for working with streams and files in memory.\n",
    "# - `pygame`: Used for playing audio files.\n",
    "# - `transformers`: Provides pre-trained models for various NLP tasks.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import Document\n",
    "import docx\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "import io\n",
    "import pygame\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the summarization pipeline using Hugging Face's Transformers library.\n",
    "# This will use the \"facebook/bart-large-cnn\" model for generating summaries.\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Google API Key as an environment variable.\n",
    "# This key is used for authenticating requests to Google's Generative AI services.\n",
    "# Replace the placeholder with your actual API key.\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAwZeFnJNdT7cc7ze4MMyCD8ZX9a_66WTw\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Process a PDF file to create a FAISS index.\n",
    "    \n",
    "    Parameters:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    db (FAISS): FAISS index of the PDF content.\n",
    "    \"\"\"\n",
    "    # Load and split the PDF into pages\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load_and_split()\n",
    "    \n",
    "    # Create embeddings for the document content using HuggingFace's pre-trained model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Create a FAISS index from the document pages\n",
    "    db = FAISS.from_documents(pages, embeddings)\n",
    "    return db\n",
    "\n",
    "def process_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Process a CSV file to create a FAISS index.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    db (FAISS): FAISS index of the CSV content.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Convert each row of the DataFrame into a Document object\n",
    "    documents = [Document(page_content=\" | \".join([f\"{col}: {val}\" for col, val in row.items()])) for _, row in df.iterrows()]\n",
    "    \n",
    "    # Create embeddings for the document content using HuggingFace's pre-trained model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Create a FAISS index from the document rows\n",
    "    db = FAISS.from_documents(documents, embeddings)\n",
    "    return db\n",
    "\n",
    "def process_txt(txt_path):\n",
    "    \"\"\"\n",
    "    Process a TXT file to create a FAISS index.\n",
    "    \n",
    "    Parameters:\n",
    "    txt_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    db (FAISS): FAISS index of the TXT content.\n",
    "    \"\"\"\n",
    "    # Read the entire text file\n",
    "    with open(txt_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Create a single Document object from the text\n",
    "    documents = [Document(page_content=text)]\n",
    "    \n",
    "    # Create embeddings for the document content using HuggingFace's pre-trained model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Create a FAISS index from the document\n",
    "    db = FAISS.from_documents(documents, embeddings)\n",
    "    return db\n",
    "\n",
    "def process_docx(docx_path):\n",
    "    \"\"\"\n",
    "    Process a DOCX file to create a FAISS index.\n",
    "    \n",
    "    Parameters:\n",
    "    docx_path (str): Path to the DOCX file.\n",
    "\n",
    "    Returns:\n",
    "    db (FAISS): FAISS index of the DOCX content.\n",
    "    \"\"\"\n",
    "    # Load the DOCX file and extract text from paragraphs\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    \n",
    "    # Create a single Document object from the text\n",
    "    documents = [Document(page_content=text)]\n",
    "    \n",
    "    # Create embeddings for the document content using HuggingFace's pre-trained model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Create a FAISS index from the document\n",
    "    db = FAISS.from_documents(documents, embeddings)\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(file_path, file_type, query):\n",
    "    \"\"\"\n",
    "    Handle a user query by processing the document and retrieving relevant information.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the document file.\n",
    "    file_type (str): Type of the document file ('pdf', 'csv', 'txt', or 'docx').\n",
    "    query (str): The user's query related to the document content.\n",
    "\n",
    "    Returns:\n",
    "    str: The response generated by the language model based on the query.\n",
    "    \"\"\"\n",
    "    # Process the document based on its type and create a FAISS index\n",
    "    if file_type == 'pdf':\n",
    "        db = process_pdf(file_path)\n",
    "    elif file_type == 'csv':\n",
    "        db = process_csv(file_path)\n",
    "    elif file_type == 'txt':\n",
    "        db = process_txt(file_path)\n",
    "    elif file_type == 'docx':\n",
    "        db = process_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "    # Perform a similarity search in the FAISS index to find relevant documents\n",
    "    docs = db.similarity_search(query)\n",
    "    content = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Create a prompt for the language model to generate an answer\n",
    "    qa_prompt = (\"Use the following pieces of context to answer the user's question. \"\n",
    "                 \"If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
    "                 \"----------------\")\n",
    "    input_text = qa_prompt + \"\\nContext:\" + content + \"\\nUser question:\\n\" + query\n",
    "\n",
    "    # Initialize the language model and get the response\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "    result = llm.invoke(input_text)\n",
    "\n",
    "    return result.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_speech_from_mic():\n",
    "    \"\"\"\n",
    "    Recognize speech from the microphone and convert it to text.\n",
    "    \n",
    "    Returns:\n",
    "    str: The recognized text from the user's speech, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    # Initialize the speech recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    # Capture audio from the microphone\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for your query...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        \n",
    "        try:\n",
    "            # Convert the captured audio to text using Google's speech recognition API\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(\"You said:\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            # Handle cases where the audio could not be understood\n",
    "            print(\"Sorry, could not understand the audio.\")\n",
    "            return None\n",
    "        except sr.RequestError:\n",
    "            # Handle cases where there was an error with the request to the API\n",
    "            print(\"Sorry, there was an error with the request.\")\n",
    "            return None\n",
    "\n",
    "def speak_text(text):\n",
    "    \"\"\"\n",
    "    Convert the provided text to speech and play it back.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): The text to be converted to speech.\n",
    "    \"\"\"\n",
    "    # Initialize text-to-speech conversion\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    \n",
    "    # Create an in-memory file-like object for the audio data\n",
    "    fp = io.BytesIO()\n",
    "    tts.write_to_fp(fp)\n",
    "    fp.seek(0)\n",
    "    \n",
    "    # Initialize the mixer for playback\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(fp)\n",
    "    \n",
    "    # Play the converted speech\n",
    "    pygame.mixer.music.play()\n",
    "    \n",
    "    # Keep the program running while the speech is playing\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your query...\n",
      "You said: what are disjoint sets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Disjoint sets are sets that do not have any elements in common. In other words, they are sets that are completely separate from each other. For example, the set {1, 2, 3} is disjoint from the set {4, 5, 6}.\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the file and the type\n",
    "file_path = r\"C:\\Users\\MNR\\Downloads\\UNIT-V-Disjoint_Set_Union_Find.docx\"  # Path to the input document\n",
    "file_type = 'docx'  # Type of the document: 'pdf', 'csv', 'txt', or 'docx'\n",
    "\n",
    "# Capture voice query from the user\n",
    "query = recognize_speech_from_mic()  # Calls the function to recognize speech from the microphone\n",
    "\n",
    "if query:\n",
    "    # If a valid query is recognized, handle the query and get the result\n",
    "    result = handle_query(file_path=file_path, file_type=file_type, query=query)\n",
    "    print(\"Answer:\", result)  # Print the result of the query to the console\n",
    "    \n",
    "    # Convert the result to speech and play it back\n",
    "    speak_text(result)\n",
    "else:\n",
    "    # If no valid query is recognized, inform the user\n",
    "    speak_text(\"Sorry, I couldn't understand your query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your query...\n",
      "You said: what is Apache spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Apache Spark is a cluster computing framework for large -scale data processing.\n"
     ]
    }
   ],
   "source": [
    "# Interactive example for PDF\n",
    "file_path = r\"C:\\Users\\MNR\\Downloads\\BDHS_Unit-5.pdf\"  # Path to the PDF file for demonstration\n",
    "file_type = 'pdf'  # Specifies that the file type is PDF\n",
    "\n",
    "# Capture voice query from the user\n",
    "query = recognize_speech_from_mic()  # Calls the function to listen and recognize speech input from the user\n",
    "\n",
    "if query:\n",
    "    # If a valid query is recognized, handle the query and get the result\n",
    "    result = handle_query(file_path=file_path, file_type=file_type, query=query)\n",
    "    print(\"Answer:\", result)  # Output the result of the query to the console\n",
    "    \n",
    "    # Convert the result to speech and play it back\n",
    "    speak_text(result)\n",
    "else:\n",
    "    # If no valid query is recognized, inform the user with a spoken message\n",
    "    speak_text(\"Sorry, I couldn't understand your query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your query...\n",
      "You said: what is the latitude of irony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I do not know the answer to this question.\n"
     ]
    }
   ],
   "source": [
    "# Interactive example for CSV\n",
    "file_path = r\"C:\\Users\\MNR\\Downloads\\Weather Station Locations.csv\"  # Path to the CSV file for demonstration\n",
    "file_type = 'csv'  # Specifies that the file type is CSV\n",
    "\n",
    "# Capture voice query from the user\n",
    "query = recognize_speech_from_mic()  # Calls the function to listen and recognize speech input from the user\n",
    "\n",
    "if query:\n",
    "    # If a valid query is recognized, handle the query and get the result\n",
    "    result = handle_query(file_path=file_path, file_type=file_type, query=query)\n",
    "    print(\"Answer:\", result)  # Output the result of the query to the console\n",
    "    \n",
    "    # Convert the result to speech and play it back\n",
    "    speak_text(result)\n",
    "else:\n",
    "    # If no valid query is recognized, inform the user with a spoken message\n",
    "    speak_text(\"Sorry, I couldn't understand your query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your query...\n",
      "You said: what is machine learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MNR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Machine Learning is the science (and art) of programming computers so they can learn from data.\n"
     ]
    }
   ],
   "source": [
    "# Interactive example for TXT\n",
    "file_path = r\"C:\\Users\\MNR\\Downloads\\mll.txt\"  # Path to the TXT file for demonstration\n",
    "file_type = 'txt'  # Specifies that the file type is TXT\n",
    "\n",
    "# Capture voice query from the user\n",
    "query = recognize_speech_from_mic()  # Calls the function to listen and recognize speech input from the user\n",
    "\n",
    "if query:\n",
    "    # If a valid query is recognized, handle the query and get the result\n",
    "    result = handle_query(file_path=file_path, file_type=file_type, query=query)\n",
    "    print(\"Answer:\", result)  # Output the result of the query to the console\n",
    "    \n",
    "    # Convert the result to speech and play it back\n",
    "    speak_text(result)\n",
    "else:\n",
    "    # If no valid query is recognized, inform the user with a spoken message\n",
    "    speak_text(\"Sorry, I couldn't understand your query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(file_path, file_type):\n",
    "    # Process the file based on its type and convert it into a searchable database\n",
    "    if file_type == 'pdf':\n",
    "        db = process_pdf(file_path)  # Process PDF file\n",
    "    elif file_type == 'csv':\n",
    "        db = process_csv(file_path)  # Process CSV file\n",
    "    elif file_type == 'txt':\n",
    "        db = process_txt(file_path)  # Process TXT file\n",
    "    elif file_type == 'docx':\n",
    "        db = process_docx(file_path)  # Process DOCX file\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")  # Raise an error for unsupported file types\n",
    "    \n",
    "    # Combine the content from all documents in the database for summarization\n",
    "    content = \"\\n\".join([doc.page_content for doc in db.similarity_search(\"\")])\n",
    "    \n",
    "    # Perform summarization on the combined content using a pre-trained model\n",
    "    summary = summarizer(content, max_length=150, min_length=50, do_sample=False)\n",
    "    \n",
    "    # Return the summarized text\n",
    "    return summary[0]['summary_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 77. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Machine Learning is the science (and art) of programming computers so they can learn from data. Machine learning is the concept that a computer program can learn and adapt to new data without human intervention. It is the field of study that gives computers the ability to learn without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the TXT file you want to summarize\n",
    "file_path = r\"C:\\Users\\MNR\\Downloads\\mll.txt\"  # Update this path to your TXT file\n",
    "\n",
    "# Specify the file type as 'txt'\n",
    "file_type = 'txt'\n",
    "\n",
    "# Call the summarize_text function to get a summary of the document\n",
    "summary = summarize_text(file_path=file_path, file_type=file_type)\n",
    "\n",
    "# Print the summary to the console\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
